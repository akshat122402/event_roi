{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Sponsor_Cost</th>\n",
       "      <th>Expected Footfall</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Is_Festivals and fairs</th>\n",
       "      <th>Is_Virtual event</th>\n",
       "      <th>Is_Conferences and seminars</th>\n",
       "      <th>Is_Sports events</th>\n",
       "      <th>Is_Community and charity events</th>\n",
       "      <th>Is_Entertainment and media events</th>\n",
       "      <th>Has_Media Sponsorship</th>\n",
       "      <th>Has_Food Stalls</th>\n",
       "      <th>Has_Philanthropy</th>\n",
       "      <th>Has_Merchandise</th>\n",
       "      <th>Has_In Kind</th>\n",
       "      <th>Has_Influencer</th>\n",
       "      <th>Has_Financial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66724.65</td>\n",
       "      <td>10852</td>\n",
       "      <td>170896.91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41450.98</td>\n",
       "      <td>53523</td>\n",
       "      <td>144000.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46095.91</td>\n",
       "      <td>21050</td>\n",
       "      <td>184722.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21426.36</td>\n",
       "      <td>1555</td>\n",
       "      <td>31870.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74581.69</td>\n",
       "      <td>1400</td>\n",
       "      <td>176779.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_Sponsor_Cost  Expected Footfall    Budget  Is_Festivals and fairs  \\\n",
       "0          66724.65              10852 170896.91                       1   \n",
       "1          41450.98              53523 144000.68                       0   \n",
       "2          46095.91              21050 184722.98                       0   \n",
       "3          21426.36               1555  31870.87                       0   \n",
       "4          74581.69               1400 176779.21                       0   \n",
       "\n",
       "   Is_Virtual event  Is_Conferences and seminars  Is_Sports events  \\\n",
       "0                 0                            0                 0   \n",
       "1                 0                            0                 1   \n",
       "2                 0                            0                 0   \n",
       "3                 0                            0                 0   \n",
       "4                 0                            1                 0   \n",
       "\n",
       "   Is_Community and charity events  Is_Entertainment and media events  \\\n",
       "0                                0                                  0   \n",
       "1                                0                                  0   \n",
       "2                                0                                  1   \n",
       "3                                0                                  0   \n",
       "4                                0                                  0   \n",
       "\n",
       "   Has_Media Sponsorship  Has_Food Stalls  Has_Philanthropy  Has_Merchandise  \\\n",
       "0                      0                0                 0                1   \n",
       "1                      0                1                 0                1   \n",
       "2                      1                0                 1                1   \n",
       "3                      0                0                 1                0   \n",
       "4                      0                0                 1                0   \n",
       "\n",
       "   Has_In Kind  Has_Influencer  Has_Financial  \n",
       "0            1               0              1  \n",
       "1            1               1              0  \n",
       "2            1               1              0  \n",
       "3            1               0              0  \n",
       "4            1               0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('event_sponsorship_roi_dataset.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "df['Avg_Sponsor_Cost'] = df.apply(lambda row: np.mean([float(cost) for cost in row['Sponsor Costs'].split('|')]), axis=1)\n",
    "\n",
    "# Create binary columns for each sponsorship type\n",
    "sponsor_types = [\"Media Sponsorship\", \"Food Stalls\", \"Philanthropy\", \"Merchandise\", \"In Kind\", \"Influencer\", \"Financial\"]\n",
    "for sponsor_type in sponsor_types:\n",
    "    df[f'Has_{sponsor_type}'] = df['Sponsor Types'].apply(lambda x: int(sponsor_type in x))\n",
    "\n",
    "event_types = [\"Festivals and fairs\", \"Virtual event\", \"Conferences and seminars\", \"Sports events\", \"Community and charity events\", \"Entertainment and media events\"]\n",
    "for event_type in event_types:\n",
    "    df[f'Is_{event_type}'] = df['Event Type'].apply(lambda x: int(event_type in x))\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['Event Type'], dtype=int)\n",
    "# Prepare features and target\n",
    "X = df[['Avg_Sponsor_Cost', 'Expected Footfall', 'Budget'] + \n",
    "       [f'Is_{event_type}' for event_type in event_types] +\n",
    "       [f'Has_{sponsor_type}' for sponsor_type in sponsor_types]]\n",
    "y = df['Total Revenue']\n",
    "\n",
    "# Split the data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:49<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 801\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176983.739909\n",
      "Model Comparison:\n",
      "                               Adjusted R-Squared  R-Squared      RMSE  \\\n",
      "Model                                                                    \n",
      "HuberRegressor                               0.92       0.92  35085.27   \n",
      "PassiveAggressiveRegressor                   0.92       0.92  35085.58   \n",
      "LassoLarsIC                                  0.92       0.92  35106.84   \n",
      "LassoLarsCV                                  0.92       0.92  35108.01   \n",
      "LarsCV                                       0.92       0.92  35108.01   \n",
      "LassoCV                                      0.92       0.92  35108.42   \n",
      "LassoLars                                    0.92       0.92  35111.82   \n",
      "Lasso                                        0.92       0.92  35111.83   \n",
      "LinearRegression                             0.92       0.92  35111.89   \n",
      "TransformedTargetRegressor                   0.92       0.92  35111.89   \n",
      "Lars                                         0.92       0.92  35111.89   \n",
      "Ridge                                        0.92       0.92  35112.83   \n",
      "RidgeCV                                      0.92       0.92  35112.83   \n",
      "BayesianRidge                                0.92       0.92  35113.19   \n",
      "OrthogonalMatchingPursuitCV                  0.92       0.92  35114.99   \n",
      "OrthogonalMatchingPursuit                    0.92       0.92  35114.99   \n",
      "SGDRegressor                                 0.92       0.92  35137.48   \n",
      "GradientBoostingRegressor                    0.92       0.92  35439.77   \n",
      "LGBMRegressor                                0.92       0.92  35995.04   \n",
      "HistGradientBoostingRegressor                0.91       0.92  36179.57   \n",
      "RandomForestRegressor                        0.91       0.91  36635.66   \n",
      "AdaBoostRegressor                            0.91       0.91  36817.18   \n",
      "ExtraTreesRegressor                          0.91       0.91  37583.27   \n",
      "XGBRegressor                                 0.90       0.91  38193.18   \n",
      "BaggingRegressor                             0.90       0.90  38385.91   \n",
      "RANSACRegressor                              0.90       0.90  38566.87   \n",
      "DecisionTreeRegressor                        0.84       0.84  50095.59   \n",
      "ElasticNet                                   0.83       0.83  50650.61   \n",
      "ExtraTreeRegressor                           0.83       0.83  50831.77   \n",
      "PoissonRegressor                             0.80       0.80  55127.49   \n",
      "KNeighborsRegressor                          0.78       0.78  58078.82   \n",
      "GammaRegressor                               0.76       0.77  60241.80   \n",
      "TweedieRegressor                             0.75       0.75  61581.55   \n",
      "ElasticNetCV                                 0.02       0.03 122699.24   \n",
      "DummyRegressor                              -0.01      -0.00 124386.14   \n",
      "NuSVR                                       -0.02      -0.01 124882.86   \n",
      "SVR                                         -0.04      -0.03 126117.15   \n",
      "QuantileRegressor                           -0.04      -0.03 126308.08   \n",
      "KernelRidge                                 -1.14      -1.12 181312.22   \n",
      "MLPRegressor                                -1.45      -1.43 193985.73   \n",
      "LinearSVR                                   -1.88      -1.86 210261.98   \n",
      "GaussianProcessRegressor                   -40.35     -40.01 796582.69   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "HuberRegressor                       0.07  \n",
      "PassiveAggressiveRegressor           0.20  \n",
      "LassoLarsIC                          0.03  \n",
      "LassoLarsCV                          0.07  \n",
      "LarsCV                               0.04  \n",
      "LassoCV                              0.08  \n",
      "LassoLars                            0.01  \n",
      "Lasso                                0.02  \n",
      "LinearRegression                     0.03  \n",
      "TransformedTargetRegressor           0.02  \n",
      "Lars                                 0.02  \n",
      "Ridge                                0.02  \n",
      "RidgeCV                              0.06  \n",
      "BayesianRidge                        0.17  \n",
      "OrthogonalMatchingPursuitCV          0.09  \n",
      "OrthogonalMatchingPursuit            0.03  \n",
      "SGDRegressor                         0.03  \n",
      "GradientBoostingRegressor            1.67  \n",
      "LGBMRegressor                        0.13  \n",
      "HistGradientBoostingRegressor        0.29  \n",
      "RandomForestRegressor                5.82  \n",
      "AdaBoostRegressor                    0.29  \n",
      "ExtraTreesRegressor                  2.99  \n",
      "XGBRegressor                         0.16  \n",
      "BaggingRegressor                     0.47  \n",
      "RANSACRegressor                      0.15  \n",
      "DecisionTreeRegressor                0.08  \n",
      "ElasticNet                           0.01  \n",
      "ExtraTreeRegressor                   0.05  \n",
      "PoissonRegressor                     0.09  \n",
      "KNeighborsRegressor                  0.05  \n",
      "GammaRegressor                       0.06  \n",
      "TweedieRegressor                     0.03  \n",
      "ElasticNetCV                         0.08  \n",
      "DummyRegressor                       0.01  \n",
      "NuSVR                                2.79  \n",
      "SVR                                  3.75  \n",
      "QuantileRegressor                    2.56  \n",
      "KernelRidge                          4.76  \n",
      "MLPRegressor                        11.24  \n",
      "LinearSVR                            0.01  \n",
      "GaussianProcessRegressor            11.09  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create preprocessing steps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and run LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(models)\n",
    "\n",
    "# # Print actual range of ROI in the dataset\n",
    "# print(f\"\\nActual ROI range in the dataset:\")\n",
    "# print(f\"Minimum ROI: {y.min():.2f}%\")\n",
    "# print(f\"Maximum ROI: {y.max():.2f}%\")\n",
    "# print(f\"Mean ROI: {y.mean():.2f}%\")\n",
    "\n",
    "# # Get the best performing model\n",
    "# best_model_name = models.index[0]\n",
    "# best_model_r2 = models.iloc[0]['R-Squared']\n",
    "# print(f\"\\nBest performing model: {best_model_name}\")\n",
    "# print(f\"Best model R-squared score: {best_model_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR : 92.03136653696045\n",
      "LASSO : 92.03132371113234\n",
      "RIDGE : 92.00762787228383\n",
      "EL : 29.864347238266\n",
      "SVR : -2.924269090212328\n",
      "DTR : 83.48125286452182\n",
      "RFR : 91.30145037083129\n"
     ]
    }
   ],
   "source": [
    "r1=LinearRegression()\n",
    "r2=Lasso()\n",
    "r3=Ridge()\n",
    "r4=ElasticNet()\n",
    "r5=SVR()\n",
    "r6=DecisionTreeRegressor()\n",
    "r7=RandomForestRegressor()\n",
    "reg=[r1,r2,r3,r4,r5,r6,r7]\n",
    "names=['LR','LASSO','RIDGE','EL','SVR','DTR','RFR']\n",
    "mse={}\n",
    "r2s={}\n",
    "t={}\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "for model,name in zip(reg,names):\n",
    "  t1=time.time()\n",
    "  model.fit(X_train_scaled,y_train)\n",
    "  y_pred=model.predict(X_test_scaled)\n",
    "  t2=time.time()\n",
    "  mse[name]=mean_squared_error(y_test,y_pred)\n",
    "  r2s[name]=r2_score(y_test,y_pred)\n",
    "  t[name]=t2-t1\n",
    "\n",
    "for i,j in r2s.items():\n",
    "  print(i,':',j*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost R-Squared: 0.9142\n",
      "CatBoost RMSE: 36433.16\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Initialize CatBoost\n",
    "catboost_model = CatBoostRegressor(verbose=0, random_seed=42)\n",
    "\n",
    "# Fit the model\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"CatBoost R-Squared: {r2:.4f}\")\n",
    "print(f\"CatBoost RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor R-Squared: 0.9194\n",
      "Stacking Regressor RMSE: 35309.33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Define your feature columns and target column\n",
    "feature_cols = []\n",
    "for col in X:\n",
    "    feature_cols.append(col)\n",
    "target_col = 'Total Revenue'\n",
    "\n",
    "# Separate the features and target\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Preprocessing for numerical data: impute missing values\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, feature_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=50, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "stacking_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=RidgeCV()\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
    "rmse_stacking = np.sqrt(mean_squared_error(y_test, y_pred_stacking))\n",
    "\n",
    "print(f\"Stacking Regressor R-Squared: {r2_stacking:.4f}\")\n",
    "print(f\"Stacking Regressor RMSE: {rmse_stacking:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177465.061412\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 175926.828518\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176046.304041\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177790.018058\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 177690.487517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 176983.739909\n",
      "LightGBM R-Squared: 0.9187\n",
      "LightGBM RMSE: 35473.45\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search_lgb = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='r2')\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lgb_model = grid_search_lgb.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred_lgb = best_lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
    "\n",
    "print(f\"LightGBM R-Squared: {r2_lgb:.4f}\")\n",
    "print(f\"LightGBM RMSE: {rmse_lgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost R-Squared: 0.9188\n",
      "XGBoost RMSE: 35452.57\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='r2')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "print(f\"XGBoost R-Squared: {r2_xgb:.4f}\")\n",
    "print(f\"XGBoost RMSE: {rmse_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 7s 9ms/step - loss: 5970515968.0000 - mae: 47873.5547 - val_loss: 1150790912.0000 - val_mae: 24823.8418\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1298115584.0000 - mae: 26036.9902 - val_loss: 1217724928.0000 - val_mae: 25453.0293\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1300310144.0000 - mae: 26007.1270 - val_loss: 1171683200.0000 - val_mae: 24964.8516\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1309043456.0000 - mae: 26087.6934 - val_loss: 1170593280.0000 - val_mae: 24975.0723\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1308331136.0000 - mae: 26085.0156 - val_loss: 1195900288.0000 - val_mae: 25126.7773\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1306669696.0000 - mae: 26088.1777 - val_loss: 1210403328.0000 - val_mae: 25247.4102\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1301240832.0000 - mae: 26029.9180 - val_loss: 1181329664.0000 - val_mae: 25009.7051\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1290757376.0000 - mae: 25957.5684 - val_loss: 1188234368.0000 - val_mae: 25149.9141\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1300047744.0000 - mae: 26034.5859 - val_loss: 1186957312.0000 - val_mae: 25008.0156\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1310191360.0000 - mae: 26068.2773 - val_loss: 1162387456.0000 - val_mae: 24801.0898\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1310361344.0000 - mae: 26115.5879 - val_loss: 1244372224.0000 - val_mae: 25555.7168\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1314789632.0000 - mae: 26153.1367 - val_loss: 1169964672.0000 - val_mae: 24899.8066\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1295979520.0000 - mae: 26009.3730 - val_loss: 1155626624.0000 - val_mae: 24751.3945\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1296561792.0000 - mae: 25929.0723 - val_loss: 1189048192.0000 - val_mae: 25047.7656\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1293093760.0000 - mae: 26009.0566 - val_loss: 1199193600.0000 - val_mae: 25120.3027\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1304793088.0000 - mae: 26028.0879 - val_loss: 1271543552.0000 - val_mae: 25729.7070\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1303859968.0000 - mae: 26097.0723 - val_loss: 1241106816.0000 - val_mae: 25411.0293\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1303501312.0000 - mae: 26066.9180 - val_loss: 1182583424.0000 - val_mae: 24975.7324\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1302352384.0000 - mae: 26028.4902 - val_loss: 1165105152.0000 - val_mae: 24853.6172\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1301915264.0000 - mae: 26004.8945 - val_loss: 1178121088.0000 - val_mae: 24978.6250\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1305365760.0000 - mae: 26041.0020 - val_loss: 1162442240.0000 - val_mae: 24857.1250\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1304853120.0000 - mae: 26056.8223 - val_loss: 1168865664.0000 - val_mae: 24917.6406\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1301919488.0000 - mae: 26042.2793 - val_loss: 1168541184.0000 - val_mae: 24956.0449\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1301337344.0000 - mae: 25995.6816 - val_loss: 1168988928.0000 - val_mae: 24927.1953\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1292712064.0000 - mae: 25968.1543 - val_loss: 1186434816.0000 - val_mae: 25031.0020\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1303263104.0000 - mae: 26014.2070 - val_loss: 1157427072.0000 - val_mae: 24769.5996\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1302203776.0000 - mae: 25996.7871 - val_loss: 1174696448.0000 - val_mae: 24932.6094\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1303513344.0000 - mae: 26081.1426 - val_loss: 1193639936.0000 - val_mae: 25095.1992\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1298406016.0000 - mae: 25978.9434 - val_loss: 1172233984.0000 - val_mae: 24910.2344\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1307341056.0000 - mae: 26112.3516 - val_loss: 1229502464.0000 - val_mae: 25387.1699\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1308624512.0000 - mae: 26051.9902 - val_loss: 1180466560.0000 - val_mae: 25023.8223\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1300372352.0000 - mae: 25989.4355 - val_loss: 1157291264.0000 - val_mae: 24736.0293\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1324338048.0000 - mae: 26140.3184 - val_loss: 1162562304.0000 - val_mae: 24831.1895\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1300137472.0000 - mae: 26023.5020 - val_loss: 1169648768.0000 - val_mae: 24916.4434\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1314058240.0000 - mae: 26123.3496 - val_loss: 1164421504.0000 - val_mae: 24788.1621\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1300825984.0000 - mae: 25993.8398 - val_loss: 1204942208.0000 - val_mae: 25158.2344\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1302398080.0000 - mae: 25974.3691 - val_loss: 1159926272.0000 - val_mae: 24817.0625\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1303046656.0000 - mae: 26015.6250 - val_loss: 1176651904.0000 - val_mae: 25016.2578\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1303915264.0000 - mae: 26028.0918 - val_loss: 1164931456.0000 - val_mae: 24849.7402\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1308902912.0000 - mae: 25998.6875 - val_loss: 1169632256.0000 - val_mae: 24917.8066\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1295908096.0000 - mae: 25967.2656 - val_loss: 1157243008.0000 - val_mae: 24768.6074\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1306775168.0000 - mae: 26021.2500 - val_loss: 1168399360.0000 - val_mae: 24902.8516\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 1298012672.0000 - mae: 26005.0371 - val_loss: 1167763840.0000 - val_mae: 24887.6816\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1298320384.0000 - mae: 26023.5605 - val_loss: 1200194304.0000 - val_mae: 25172.7324\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1291153152.0000 - mae: 25916.8691 - val_loss: 1239554176.0000 - val_mae: 25331.1523\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1302842880.0000 - mae: 26134.3223 - val_loss: 1272728320.0000 - val_mae: 25663.1484\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1312432512.0000 - mae: 26158.8223 - val_loss: 1159294848.0000 - val_mae: 24781.6172\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 1306327552.0000 - mae: 26058.5801 - val_loss: 1174053248.0000 - val_mae: 24834.1934\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1296409472.0000 - mae: 25969.5898 - val_loss: 1244085504.0000 - val_mae: 25444.5605\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1307137024.0000 - mae: 26086.1504 - val_loss: 1168494720.0000 - val_mae: 24884.1699\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "Deep Learning Model R-Squared: 0.9184\n",
      "Deep Learning Model RMSE: 35539.98\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess data for deep learning\n",
    "# Standardize numerical features\n",
    "\n",
    "# Define the neural network model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Initialize and train the model\n",
    "model = build_model()\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict\n",
    "y_pred_dl = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_dl = r2_score(y_test, y_pred_dl)\n",
    "rmse_dl = np.sqrt(mean_squared_error(y_test, y_pred_dl))\n",
    "\n",
    "print(f\"Deep Learning Model R-Squared: {r2_dl:.4f}\")\n",
    "print(f\"Deep Learning Model RMSE: {rmse_dl:.2f}\")\n",
    "\n",
    "# Plot training history (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
